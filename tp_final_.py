# -*- coding: utf-8 -*-
# """TP FINAL -

# Automatically generated by Colaboratory.

# Original file is located at
#     https://colab.research.google.com/drive/1F6CU653wtJzK1OIsTS4nUl2LnbIVxjIl

# # Nueva sección

# # Ayudas
# https://www.aprendemachinelearning.com/clasificacion-con-datos-desbalanceados/

# https://aprendeconejemplos.org/python/preprocesamiento-de-datasets-con-scikit-learn-y-pandas 

# https://unipython.com/ensemble-methods-metodos-conjunto/

# https://aprendeconejemplos.org/python/aprendizaje-automatico-con-scikit-learn-parte-i-clasificacion

# https://joserzapata.github.io/courses/python-ciencia-datos/ml/

# https://nexlab.dev/tech/2020/07/22/clasifica-datos-entrenando-una-red-neuronal 

# ##Borrar columnas

# credit = credit.drop(['nombreColumna'], axis=1)

# credit = credit.dropna(thresh=half_count,axis=1)

# Analisis de datos segun el resultado

# Actividades

# 1. Análisis del dataset provisto.
# """

# Librerias 
    

import pandas as pd
import numpy as np
from sklearn import tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_absolute_percentage_error, r2_score, mean_squared_error, mean_absolute_error, classification_report,confusion_matrix
from sklearn.preprocessing import MinMaxScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn import neighbors
from sklearn.manifold import TSNE

from matplotlib import pyplot as plt

class prueba():
    datos = "credit_risk_dataset/credit_risk_dataset.csv"
    credit = ""
    X_train= 0 
    X_test= 0 
    y_train= 0 
    y_test = 0
    y_pred = 0

    def cargaDeDatos(self):    
        # Cargar datos
        self.credit = pd.read_csv(self.datos)
        print("aca")
        print(self.credit)
        #muevo la columna loan_status al final 
        ## Ver si se deberia poner mas abajo en el codigo
        self.credit = self.credit[['person_age','person_income','person_home_ownership','person_emp_length','loan_intent','loan_grade','loan_amnt','loan_int_rate','loan_percent_income','cb_person_default_on_file','cb_person_cred_hist_length','loan_status']]
        #mostrar los primeros 10 datos
        #credit.head(10)
        #edad ingresos casa_propiedad empleo_longitud intención_préstamo grado_préstamo préstamo_amnt tasa_int_préstamo 
        # estado_préstamo ingreso_porcentaje_préstamo cb_persona_predeterminado_en_archivo cb_persona_cred_hist_longitud

    def mapeoDatos(self):
        # mappea cada elemento de la columna a un valor del dict 'd'

        m = {'EDUCATION': 0,'MEDICAL':1, 'VENTURE':2, 'PERSONAL':3, 'DEBTCONSOLIDATION':4, 'HOMEIMPROVEMENT':5 }
        self.credit['loan_intent'] = self.credit['loan_intent'].map(m) 
        
        m = {'RENT':0, 'MORTGAGE':1, 'OWN':2, 'OTHER':3}
        self.credit['person_home_ownership'] = self.credit['person_home_ownership'].map(m) 
        
        d = {'Y': 1, 'N': 0}
        self.credit['cb_person_default_on_file'] = self.credit['cb_person_default_on_file'].map(d) 
        
        d = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6,}
        self.credit['loan_grade'] = self.credit['loan_grade'].map(d) 
        

    def eliminarVacios(self):
        #credit.dropna()
        self.credit["loan_int_rate"]= self.credit["loan_int_rate"].fillna(0).astype(np.int64, errors='ignore')
        self.credit["person_emp_length"]= self.credit["person_emp_length"].fillna(0).astype(np.int64, errors='ignore')


    def escalarDatos(self):
        min_max_scaler = MinMaxScaler()
        l_values = self.credit[['loan_amnt']]
        scaled_values = min_max_scaler.fit(l_values)
        self.credit[['loan_amnt']]=min_max_scaler.transform(l_values)

        min_max_scaler = MinMaxScaler()
        l_values = self.credit[['person_income']]
        scaled_values  = min_max_scaler.fit(l_values)
        self.credit[['person_income']]=min_max_scaler.transform(l_values)


    def dividirModelo(self):
        X= self.credit.iloc[:, :-1].values
        y = self.credit.iloc[:, -1].values
        # split into train test sets
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.33, random_state=1)
        #print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

    def limpiarDatos(self):
        self.cargaDeDatos()
        self.mapeoDatos()
        self.eliminarVacios()
        self.escalarDatos()
        self.dividirModelo()
        print("listo")
    def entrenarModelo(self):
        pass


    def pca(self):
            
        pca = PCA(n_components=2)
        pca.fit(self.credit)
        #self.prediccionModelo(pca)
        print ('Relación de varianza explicada: ',pca.explained_variance_ratio_)  
        print ('Componentes que representan el vector X: ',pca.components_)

    """### Modelo SVC 

    """
    def svc(self):

        classifier =  SVC(kernel="linear", C=0.025)
        # Realizamos el entrenamiento
        classifier.fit(self.X_train, self.y_train)
        print(classifier.score(self.X_test, self.y_test))
        self.prediccionModelo(classifier)
        #curva rock scoref1 accurasi

    def prediccionModelo(self,modelo):
        y_pred = modelo.predict(self.X_test)
        print(classification_report(self.y_test, y_pred))
        accuracy_score(self.y_test, self.y_pred)
        mean= mean_squared_error(self.y_test,self.y_ped)
        print('MEAN: %.3f' % mean)
        mae = mean_absolute_error(self.y_test, self.y_pred)
        print('MAE: %.3f' % mae)

        print(confusion_matrix(self.y_test, self.y_pred))

    #Error absoluto medio (Mean Absolute Error)

        y_true = self.y_test
        mean_absolute_error(self.y_true, self.y_pred)

    #Error Cuadratico Medio (Mean Squared Error)

        mean_squared_error(self.y_test, self.y_pred)

        r2_score(self.y_true, self.y_pred)

        mean_absolute_percentage_error(self.y_true, self.y_pred)

    # Obtenemos el accuracy de nuestro modelo para el conjunto de test
    #print(classifier.score(X_test, y_test))
    #y_pred = classifier.predict(X_test)



    #                       Arboles de decision
    def arbolDecision(self):
        dtc = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)  # los parametros son opcionales
        dtc.fit(self.X_train, self.y_train)
        self.prediccionModelo(dtc)



    #                   Clasificador Random Forest
    def randomForest(self):
        rfc = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0) # los parametros son opcionales
        rfc.fit(self.X_train, self.y_train)
        self.prediccionModelo(rfc)


    #                   Naive Bayes
    def naiveBayes(self):
        gnb = GaussianNB()
        gnb.fit(self.X_train, self.y_train)
        self.prediccionModelo(gnb)


    def neighbors(self):

        knn = neighbors.KNeighborsClassifier(n_neighbors=5) # los parametros son opcionales
        knn.fit(self.X_train, self.y_train)
        self.prediccionModelo(knn)

    def tsne(self):
        ## Prueba
        tsne = TSNE(n_components=2, learning_rate='auto',init='random', perplexity=3).fit_transform(X)
        self.prediccionModelo(tsne)
    ############VER############################
        # from sklearn.model_selection import KFold
        # from sklearn.tree import DecisionTreeClassifier
        # modelo = DecisionTreeClassifier()
        # kfold_validacion = KFold(10) # Acá indicamos cuantos fold queremos. En nuestro caso elegimos 10.
        # modelo.fit(X_train, y_train)
        # y_pred = modelo.predict(X_test)
        # accuracy_score(y_test, y_pred)

        # y_pred = modelo.predict(X_test)
        # print(classification_report(y_test, y_pred))

        # classifier.score(X_test, y_test)
    #########################################
    def dibujarArbol(self,modelo):

        fig = plt.figure(figsize=(25,20))
        _ = tree.plot_tree(modelo,   
                            class_names=["Rejected","Hired"],
                            filled=True)

    def main(self):
        self.cargaDeDatos()
        self.limpiarDatos()
        self.pca()
        self.svc()
        self.arbolDecision()
        self.randomForest()
        self.naiveBayes()
        self.neighbors()
        self.tsne()

#main()

#from sklearn.tree import DecisionTreeClassifier
# dtc = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)  # los parametros son opcionales
# dtc.fit(X_train, y_train)

# # Reporte de Clasificacion

# from sklearn.metrics import classification_report
# print(classification_report(y_test, y_pred))

# Confusion Matrix