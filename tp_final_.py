# -*- coding: utf-8 -*-
"""TP FINAL -

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F6CU653wtJzK1OIsTS4nUl2LnbIVxjIl

# Nueva sección

# Ayudas
https://www.aprendemachinelearning.com/clasificacion-con-datos-desbalanceados/

https://aprendeconejemplos.org/python/preprocesamiento-de-datasets-con-scikit-learn-y-pandas 

https://unipython.com/ensemble-methods-metodos-conjunto/

https://aprendeconejemplos.org/python/aprendizaje-automatico-con-scikit-learn-parte-i-clasificacion

https://joserzapata.github.io/courses/python-ciencia-datos/ml/

https://nexlab.dev/tech/2020/07/22/clasifica-datos-entrenando-una-red-neuronal 

##Borrar columnas

credit = credit.drop(['nombreColumna'], axis=1)

credit = credit.dropna(thresh=half_count,axis=1)

Analisis de datos segun el resultado

Actividades

1. Análisis del dataset provisto.
"""

##Librerias 
    

import pandas as pd
import numpy as np
from sklearn import tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_absolute_percentage_error, r2_score, mean_squared_error, mean_absolute_error, classification_report,confusion_matrix
from sklearn.preprocessing import MinMaxScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn import neighbors
from sklearn.manifold import TSNE

from matplotlib import pyplot as plt


class prueba():
    datos = "credit_risk_dataset.csv"
    credit = ""
    X_train= 0 
    X_test= 0 
    y_train= 0 
    y_test = 0
    y_pred = 0
    modelos = {}


    def prediccionModelo(self,modelo):
        y_pred = modelo.predict(self.X_test)
        print(classification_report(self.y_test, y_pred))
        accuracy_score(self.y_test, self.y_pred)
        #mean= mean_squared_error(self.y_test,self.y_ped)
        #print('MEAN: %.3f' % mean)
        #mae = mean_absolute_error(self.y_test, self.y_pred)
        #print('MAE: %.3f' % mae)

        print(confusion_matrix(self.y_test, self.y_pred))

        #Error absoluto medio (Mean Absolute Error)

        y_true = self.y_test
        mean_absolute_error(self.y_true, self.y_pred)

        #Error Cuadratico Medio (Mean Squared Error)

        mean_squared_error(self.y_test, self.y_pred)

        r2_score(self.y_true, self.y_pred)

        mean_absolute_percentage_error(self.y_true, self.y_pred)

        # Obtenemos el accuracy de nuestro modelo para el conjunto de test
        #print(classifier.score(X_test, y_test))
        #y_pred = classifier.predict(X_test)


    def cargaDeDatos(self):    
        # Cargar datos
        self.credit = pd.read_csv(self.datos)
        print("aca")
        print(self.credit)
        #muevo la columna loan_status al final 
        ## Ver si se deberia poner mas abajo en el codigo
        self.credit = self.credit[['person_age','person_income','person_home_ownership','person_emp_length','loan_intent','loan_grade','loan_amnt','loan_int_rate','loan_percent_income','cb_person_default_on_file','cb_person_cred_hist_length','loan_status']]
        #mostrar los primeros 10 datos
        #credit.head(10)
        #edad ingresos casa_propiedad empleo_longitud intención_préstamo grado_préstamo préstamo_amnt tasa_int_préstamo 
        # estado_préstamo ingreso_porcentaje_préstamo cb_persona_predeterminado_en_archivo cb_persona_cred_hist_longitud

    def mapeoDatos(self):
        # mappea cada elemento de la columna a un valor del dict 'd'

        m = {'EDUCATION': 0,'MEDICAL':1, 'VENTURE':2, 'PERSONAL':3, 'DEBTCONSOLIDATION':4, 'HOMEIMPROVEMENT':5 }
        self.credit['loan_intent'] = self.credit['loan_intent'].map(m) 
        
        m = {'RENT':0, 'MORTGAGE':1, 'OWN':2, 'OTHER':3}
        self.credit['person_home_ownership'] = self.credit['person_home_ownership'].map(m) 
        
        d = {'Y': 1, 'N': 0}
        self.credit['cb_person_default_on_file'] = self.credit['cb_person_default_on_file'].map(d) 
        
        d = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6,}
        self.credit['loan_grade'] = self.credit['loan_grade'].map(d) 
        

    def eliminarVacios(self):
        #credit.dropna()
        self.credit["loan_int_rate"]= self.credit["loan_int_rate"].fillna(0).astype(np.int64, errors='ignore')
        self.credit["person_emp_length"]= self.credit["person_emp_length"].fillna(0).astype(np.int64, errors='ignore')


    def escalarDatos(self):
        min_max_scaler = MinMaxScaler()
        l_values = self.credit[['loan_amnt']]
        scaled_values = min_max_scaler.fit(l_values)
        self.credit[['loan_amnt']]=min_max_scaler.transform(l_values)

        min_max_scaler = MinMaxScaler()
        l_values = self.credit[['person_income']]
        scaled_values  = min_max_scaler.fit(l_values)
        self.credit[['person_income']]=min_max_scaler.transform(l_values)


    def dividirModelo(self):
        X= self.credit.iloc[:, :-1].values
        y = self.credit.iloc[:, -1].values
        # split into train test sets
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.33, random_state=1)
        #print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

    def limpiarDatos(self):
        #self.cargaDeDatos()
        self.mapeoDatos()
        self.eliminarVacios()
        self.escalarDatos()
        self.dividirModelo()
        print("listo")

    def entrenarModelo(self):
        pass


    def pca(self):         
        pca = PCA(n_components=2)
        pca.fit(self.credit)
        self.dividirModelo()

        #self.prediccionModelo(pca)
        print ('Relación de varianza explicada: ',pca.explained_variance_ratio_)  
        print ('Componentes que representan el vector X: ',pca.components_)
        
    """### Modelo SVC 

    """
    def svc(self):

        classifier =  SVC(kernel="linear", C=0.025)
        # Realizamos el entrenamiento
        print("entrenamiento")
        classifier.fit(self.X_train, self.y_train)
        self.modelos["svc"] = classifier 
        print("score")
        print(classifier.score(self.X_test, self.y_test))
        print("predicccion")
        y_pred = classifier.predict(self.X_test)
        print("reporte")
        print(classification_report(self.y_test, y_pred))
        #self.prediccionModelo(classifier)
        #curva rock scoref1 accurasi
        #print(classifier.fit(self.X_train, self.y_train))


    #                       Arboles de decision
    def arbolDecision(self):

        dtc = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)  # los parametros son opcionales
        dtc.fit(self.X_train, self.y_train)
        #self.prediccionModelo(dtc)
        dtc.fit(self.X_train, self.y_train)
        self.modelos["dtc"] = dtc
        y_pred = dtc.predict(self.X_test)
        accuracy_score(self.y_test, y_pred)
        print(classification_report(self.y_test, y_pred))
    #                   Clasificador Random Forest
   
    def randomForest(self):

        rfc = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0) # los parametros son opcionales
        rfc.fit(self.X_train, self.y_train)
        self.modelos["rfc"] = rfc
        y_pred = rfc.predict(self.X_test)
        print(accuracy_score(self.y_test, y_pred))
        print(classification_report(self.y_test, y_pred))
        #self.prediccionModelo(rfc)


    #                   Naive Bayes
    def naiveBayes(self):

        gnb = GaussianNB()
        gnb.fit(self.X_train, self.y_train)
        self.modelos["dnb"] = gnb
        y_pred = gnb.predict(self.X_test)
        accuracy_score(self.y_test, y_pred)
        print(classification_report(self.y_test, y_pred))

        #self.prediccionModelo(gnb)


    def neighbors(self):

        knn = neighbors.KNeighborsClassifier(n_neighbors=5) # los parametros son opcionales
        print("entrenando")
        knn.fit(self.X_train, self.y_train)
        self.modelos["knn"] = knn
        #self.prediccionModelo(knn)
        print("prediccion")
        y_pred = knn.predict(self.X_test)
        print("metricas")
        accuracy_score(self.y_test, y_pred)
        #y_pred = knn.predict(self.X_test)
        print("reporte")
        print(classification_report(self.y_test, y_pred))

    def tsne(self):
        ## Prueba
        tsne = TSNE(n_components=2, learning_rate='auto',init='random', perplexity=3).fit_transform(self.X_test)
        #self.prediccionModelo(tsne)


    ############VER############################
        # from sklearn.model_selection import KFold
        # from sklearn.tree import DecisionTreeClassifier
        # modelo = DecisionTreeClassifier()
        # kfold_validacion = KFold(10) # Acá indicamos cuantos fold queremos. En nuestro caso elegimos 10.
        # modelo.fit(X_train, y_train)
        # y_pred = modelo.predict(X_test)
        # accuracy_score(y_test, y_pred)

        # y_pred = modelo.predict(X_test)
        # print(classification_report(y_test, y_pred))

        # classifier.score(X_test, y_test)
    #########################################

    def dibujarArbol(self,modelo):

        fig = plt.figure(figsize=(25,20))
        _ = tree.plot_tree(modelo,   
                            class_names=["Rejected","Hired"],
                            filled=True)

    def main(self):
        self.cargaDeDatos()
        self.limpiarDatos()
        self.pca()
        self.svc()
        self.arbolDecision()
        self.randomForest()
        self.naiveBayes()
        self.neighbors()
        self.tsne()
        
    #persona= [[22,0.009173,0,123,3,3,1.000000,16,0.59,1,3]] 
    #persona= [[23,0.015177,0,2,2,0,1.000000,7,0.37,0,2]]
    # persona= [[23,0.018512,0,2,0,0,1.000000,7,0.30,0,4]]
    #pr.prediccion(pr.modelos['svc'],(persona))

    def prediccion(self,modelo, persona):
        result = modelo.predict(persona)[0]
        if result == 1:
            print("Usuario en Mora ")
        else:
            print("Apto")



#main()


#from sklearn.tree import DecisionTreeClassifier
# dtc = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)  # los parametros son opcionales
# dtc.fit(X_train, y_train)

# # Reporte de Clasificacion

# from sklearn.metrics import classification_report
# print(classification_report(y_test, y_pred))

# Confusion Matrix

